# -*- coding: utf-8 -*-
"""CNN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uDzkB6jAPDRNWtC-XzomnT11wcT80LUp

## Setup
Using pytorch and pennylane to construct the novel QNN.
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import pennylane as qml

import numpy as np
import matplotlib.pyplot as plt

kernel_size = 5
images = 1
alpha = 0.5

"""## Classical CNN Layers

"""

### Convolution 1
C1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1, padding=2)
x = torch.rand(images, 1, 28, 28)
# activations = nn.ReLU()
# activations = nn.Sigmoid()
# activations = nn.Tanh()
x1 = C1(x)
print("C1 Shape:", x1.shape)

### Pooling 1
P1 = nn.AvgPool2d(kernel_size=2, stride=2)
p1 = P1(x1)
print("P1 Shape:", p1.shape)

### Convolution 2
C2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1, padding=0)
x2 = C2(p1)
print("C2 Shape:", x2.shape)

### Pooling 2
P2 = nn.AvgPool2d(kernel_size=1, stride=1)
p2 = P2(x2)
print("P2 Shape:", p2.shape)

### Full connections
FC1 = nn.Linear(in_features=16*10*10, out_features=120)
x3 = FC1(p2.view(-1, 16*10*10))
print("F2 Shape", x3.shape)

FC2 = nn.Linear(in_features=120, out_features=64)
x4 = FC2(x3)
print("F3 Shape",x4.shape)

"""##Residual Full Connection"""

rfc = nn.Linear(in_features=64, out_features=10)
rfc_out = rfc(x4)

print("F_residual Shape:", rfc_out.shape)
print(rfc_out)

"""##QNN"""

#QNN Setup

def init_random_hermitian_observable(n_qubits):
  Hermitian = torch.randn(n_qubits, 4)
  return Hermitian

### Actual Quantum Layer - Kris
n_qubits = 6 #2^6 = 64, so will embed the length 64 vector
entangling_layers = 3 # The PQC strongly entangling layers happens 3 times.
fixed_hermitians = True

dev = qml.device("default.qubit", wires=n_qubits)
I = torch.tensor([[1,0],[0,1]])
X = torch.tensor([[0,1],[1,0]])
Y = torch.tensor([[0,-1j],[1j,0]])
Z = torch.tensor([[1,0],[0,-1]])

# Define Quantum Circuit and Link with PyTorch
@qml.qnode(dev, interface='torch')
def qnn_circuit(inputs, weights, hermitians):
  # Amplitude Embedding
  qml.AmplitudeEmbedding(inputs, wires=range(n_qubits), normalize=True)

  # Strong Entangling Layers
  qml.StronglyEntanglingLayers(weights, wires=range(n_qubits))

  # Measure Hermitian Observable

  expvals = []

  for q in range(n_qubits):
    ai, ax, ay, az = hermitians[q]
    observable = (ai*I) + (ax*X) + (ay*Y) + (az*Z)

    expvals.append(qml.expval(qml.Hermitian(observable, q)))

  return expvals

# Define weights and have 3 layers
# This defines 3 repetitions of the entangling layers on the 6 qubits, with 3 weights
weight_shapes = {
    "weights":(entangling_layers, n_qubits, 3),
    "hermitians":(n_qubits, 4)
}

# Creates the quantum layer
qnn_layer = qml.qnn.TorchLayer(qnn_circuit, weight_shapes)

#Initialize Hermitians randomly
with torch.no_grad():
    hermitian_init = init_random_hermitian_observable(n_qubits)
    qnn_layer.hermitians.copy_(hermitian_init)

if(fixed_hermitians):
  qnn_layer.hermitians.requires_grad_(False)

# Passes the 64 inputs into the quantum layer
qnn = qnn_layer(x4)
print("Quantum Layer Shape:", qnn.shape)

# Final qnn classification layer, converts the 6 qubits to 10 outputs
qnnfcl = nn.Linear(in_features=6, out_features=10)
qnn_out = qnnfcl(qnn)
print("Final Quantum Layer Shape:",qnn_out.shape)
print(qml.draw(qnn_circuit, level='device')(x4[0], qnn_layer.weights, qnn_layer.hermitians))

"""##Output"""

# Combines the two outputs using a sum based on alpha
out = (rfc_out * (1-alpha)) + (qnn_out * alpha)

print(out)
print(out.shape)