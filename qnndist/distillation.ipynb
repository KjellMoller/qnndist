{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ux9_1gAOp4zT"
      },
      "source": [
        "# Distillation Setup\n",
        "Using pytorch to construct distillation.\n",
        "Like the paper, we focus only on the peformance matching method of dataset\n",
        "distillation for the proposed QNN mode."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rIm5bBEWHyC"
      },
      "source": [
        "- We have a model (classical LeNet or Quantum LeNet)\n",
        "- We have a real training Dataset $x$ (MNIST or CIFAR-10)\n",
        "- We want to learn a tiny synthetic dataset $\\tilde{x}$ such that:\n",
        "\n",
        "  Training the model on $\\tilde{x}$ for a few GD steps from a fixed initialization gives almost the same test accuracy as training on the full real dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Q228P-c2d32"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "try:\n",
        "   import pennylane as qml\n",
        "except ImportError:\n",
        "  !pip install pennylane\n",
        "  import pennylane as qml\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from torch.func import functional_call"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAx6QGh8decN"
      },
      "source": [
        "## Load Dataset (MNIST)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xn0zyAPo7ezI"
      },
      "outputs": [],
      "source": [
        "# MNIST images are typically grayscale and need to be converted to PyTorch tensors. Normalization is also a common practice.\n",
        "transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.1307,), (0.3081,)) # Standard Mean and std for MNIST\n",
        "    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WKZ-swoMaBfi"
      },
      "outputs": [],
      "source": [
        "training_data = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_data = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3WoH3iDqbrkp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 653
        },
        "outputId": "f04ad825-8f6a-493e-de12-0207bb9b9984"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 9 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Show sample of the MNIST dataset\n",
        "figure = plt.figure(figsize=(8, 8))\n",
        "cols, rows = 3, 3\n",
        "for i in range(1, cols * rows + 1):\n",
        "    sample_idx = torch.randint(len(training_data), size=(1,)).item()\n",
        "    img, label = training_data[sample_idx]\n",
        "    figure.add_subplot(rows, cols, i)\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eHCaWXWOamWa"
      },
      "outputs": [],
      "source": [
        "# While training a model, we typically want to pass samples in “minibatches”.\n",
        "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kro6jHoVcu9r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "outputId": "a16c3e3e-9911-41cf-ff16-e3d056822292"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature batch shape: torch.Size([64, 1, 28, 28])\n",
            "Labels batch shape: torch.Size([64])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label: 4\n"
          ]
        }
      ],
      "source": [
        "# Display image and label.\n",
        "train_features, train_labels = next(iter(train_dataloader))\n",
        "print(f\"Feature batch shape: {train_features.size()}\")\n",
        "print(f\"Labels batch shape: {train_labels.size()}\")\n",
        "img = train_features[0].squeeze()\n",
        "label = train_labels[0]\n",
        "plt.imshow(img, cmap=\"gray\")\n",
        "plt.show()\n",
        "print(f\"Label: {label}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNtCZOhjdt3c"
      },
      "source": [
        "## Define the CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObDSx-fjeBd2"
      },
      "source": [
        "This is copied CNN initialization\n",
        "\n",
        "TODO: To be replaced with Kjell and Kris work"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def init_random_hermitian_observable(n_qubits):\n",
        "  Hermitian = torch.randn(n_qubits, 4)\n",
        "  return Hermitian\n",
        "\n",
        "### Actual Quantum Layer\n",
        "n_qubits = 6 #2^6 = 64, so will embed the length 64 vector\n",
        "entangling_layers = 3 # The PQC strongly entangling layers happens 3 times.\n",
        "fixed_hermitians = True\n",
        "\n",
        "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "I = torch.tensor([[1,0],[0,1]])\n",
        "X = torch.tensor([[0,1],[1,0]])\n",
        "Y = torch.tensor([[0,-1j],[1j,0]])\n",
        "Z = torch.tensor([[1,0],[0,-1]])\n",
        "\n",
        "# Define Quantum Circuit and Link with PyTorch\n",
        "@qml.qnode(dev, interface='torch')\n",
        "def qnn_circuit(inputs, weights, hermitians):\n",
        "  # Amplitude Embedding\n",
        "  qml.AmplitudeEmbedding(inputs, wires=range(n_qubits), normalize=True)\n",
        "\n",
        "  # Strong Entangling Layers\n",
        "  qml.StronglyEntanglingLayers(weights, wires=range(n_qubits))\n",
        "\n",
        "  # Measure Hermitian Observable\n",
        "\n",
        "  expvals = []\n",
        "\n",
        "  for q in range(n_qubits):\n",
        "    ai, ax, ay, az = hermitians[q]\n",
        "    observable = (ai*I) + (ax*X) + (ay*Y) + (az*Z)\n",
        "\n",
        "    expvals.append(qml.expval(qml.Hermitian(observable, q)))\n",
        "\n",
        "  return expvals"
      ],
      "metadata": {
        "id": "theoDMK4v9ng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DqSD30ZedKj1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc7c46e2-6e06-4f88-844e-2817358eccb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "QuantumLeNet(\n",
            "  (c1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "  (p1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (c2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (p2): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (fc1): Linear(in_features=1600, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=64, bias=True)\n",
            "  (rfc): Linear(in_features=64, out_features=10, bias=True)\n",
            "  (qnn_layer): <Quantum Torch Layer: func=qnn_circuit>\n",
            "  (qnn_final): Linear(in_features=6, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "# Define model\n",
        "class QuantumLeNet(nn.Module):\n",
        "    def __init__(self, alpha=0.5, fixed_hermitians=True, residual_connection=True):\n",
        "        super(QuantumLeNet, self).__init__()\n",
        "\n",
        "        ### Convolution 1\n",
        "        self.c1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1, padding=2)\n",
        "        ### Pooling 1\n",
        "        self.p1 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "        ### Convolution 2\n",
        "        self.c2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1, padding=0)\n",
        "        ### Pooling 2\n",
        "        self.p2 = nn.AvgPool2d(kernel_size=1, stride=1)\n",
        "        ### Full Connections\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(in_features=16*10*10, out_features=120)\n",
        "        self.fc2 = nn.Linear(in_features=120, out_features=64)\n",
        "\n",
        "        ### Residual Full Connection Layer (Classical Output)\n",
        "        self.rfc = nn.Linear(in_features=64, out_features=10)\n",
        "\n",
        "        if(residual_connection=True):\n",
        "          self.alpha = alpha\n",
        "        else:\n",
        "          self.alpha = 1\n",
        "\n",
        "        # Quantum Layer\n",
        "        weight_shapes = {\n",
        "            \"weights\":(entangling_layers, n_qubits, 3),\n",
        "            \"hermitians\":(n_qubits, 4)\n",
        "        }\n",
        "\n",
        "        # Creates the quantum layer\n",
        "        self.qnn_layer = qml.qnn.TorchLayer(qnn_circuit, weight_shapes)\n",
        "\n",
        "        #Initialize Hermitians randomly\n",
        "        with torch.no_grad():\n",
        "            hermitian_init = init_random_hermitian_observable(n_qubits)\n",
        "            self.qnn_layer.hermitians.copy_(hermitian_init)\n",
        "\n",
        "        if(fixed_hermitians):\n",
        "          self.qnn_layer.hermitians.requires_grad = False\n",
        "        else:\n",
        "          self.qnn_layer.hermitians.requires_grad = True\n",
        "\n",
        "        self.qnn_final = nn.Linear(in_features=6, out_features=10)\n",
        "\n",
        "    def forward(self, x):\n",
        "      x1 = self.c1(x)\n",
        "      # print(\"C1 Shape:\", x1.shape)\n",
        "\n",
        "      p1 = self.p1(x1)\n",
        "      # print(\"P1 Shape:\", p1.shape)\n",
        "\n",
        "      x2 = self.c2(p1)\n",
        "      # print(\"C2 Shape:\", x2.shape)\n",
        "\n",
        "      p2 = self.p2(x2)\n",
        "      # print(\"P2 Shape:\", p2.shape)\n",
        "\n",
        "      flatten = self.flatten(p2)\n",
        "\n",
        "      x3 = self.fc1(flatten)\n",
        "      # print(\"FC1 Shape:\", x3.shape)\n",
        "      x4 = self.fc2(x3)\n",
        "      # print(\"FC2 Shape:\", x4.shape)\n",
        "\n",
        "      # Classical Output\n",
        "      rfc_out = self.rfc(x4)\n",
        "\n",
        "      # Quantum Output\n",
        "      qnn_out = self.qnn_layer(x4)\n",
        "      qnn_final = self.qnn_final(qnn_out)\n",
        "\n",
        "      # Combination\n",
        "      out = (rfc_out * (1 - self.alpha)) + (qnn_final * self.alpha)\n",
        "\n",
        "      return out\n",
        "\n",
        "model = QuantumLeNet().to(device)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VodTOyoiendg"
      },
      "outputs": [],
      "source": [
        "# To train a model we need a loss function and optimizer\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8CskhyyrfuiT"
      },
      "outputs": [],
      "source": [
        "# Single training loop, the model makes predictions on the training dataset (fed to it in batches)\n",
        "# and backpropagates the prediction error to adjust the model’s parameters\n",
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # Compute prediction error\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), (batch + 1) * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulrrrYAykEIT"
      },
      "source": [
        "## Check model performance on full MNIST Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VhQmfHb9f3Ot"
      },
      "outputs": [],
      "source": [
        "# Check the model’s performance against the test dataset\n",
        "def test(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2rMsSJwf3r9",
        "outputId": "e1a04c49-c031-4099-b2ba-ee3159ba144c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.382247  [   64/60000]\n",
            "loss: 2.244465  [ 6464/60000]\n",
            "loss: 2.220125  [12864/60000]\n",
            "loss: 2.172464  [19264/60000]\n",
            "loss: 2.116586  [25664/60000]\n",
            "loss: 2.017250  [32064/60000]\n",
            "loss: 2.015524  [38464/60000]\n",
            "loss: 1.987009  [44864/60000]\n",
            "loss: 1.930768  [51264/60000]\n",
            "loss: 1.917993  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 60.9%, Avg loss: 1.931172 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 1.974500  [   64/60000]\n",
            "loss: 1.948904  [ 6464/60000]\n",
            "loss: 1.935351  [12864/60000]\n",
            "loss: 1.796359  [19264/60000]\n",
            "loss: 1.750262  [25664/60000]\n",
            "loss: 1.623058  [32064/60000]\n",
            "loss: 1.579317  [38464/60000]\n",
            "loss: 1.452662  [44864/60000]\n",
            "loss: 1.263927  [51264/60000]\n",
            "loss: 1.094786  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 80.4%, Avg loss: 1.079122 \n",
            "\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "epochs = 2\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_dataloader, model, loss_fn, optimizer)\n",
        "    test(test_dataloader, model, loss_fn)\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A74JnfzJgLjs",
        "outputId": "33bfdfa8-d2ec-45a1-cc22-7532ed36f623"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved PyTorch Test Model State to test_model.pth\n"
          ]
        }
      ],
      "source": [
        "# Save the model\n",
        "torch.save(model.state_dict(), \"test_model.pth\")\n",
        "print(\"Saved PyTorch Test Model State to test_model.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Srqw3_orhGgm",
        "outputId": "09dba29b-5a8b-4aa7-e02a-4502ea369b91"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ],
      "source": [
        "# Load the model\n",
        "test_model = QuantumLeNet().to(device)\n",
        "test_model.load_state_dict(torch.load(\"test_model.pth\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kb8cjmb-g5xm",
        "outputId": "6fbdf340-9b0a-44a3-b103-e541183d501c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: \"7\", Actual: \"7\"\n"
          ]
        }
      ],
      "source": [
        "classes = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
        "test_model.eval()\n",
        "x, y = test_data[0][0], test_data[0][1]\n",
        "with torch.no_grad():\n",
        "    x = x.unsqueeze(0).to(device) # TODO: Check if unsqueeze has the correct impact.\n",
        "    pred = model(x)\n",
        "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
        "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n8kbQdNvhcLY"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, device, test_loader):\n",
        "    model.eval()\n",
        "\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            # Move data to the same device as the model\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    accuracy = 100. * correct / len(test_loader.dataset)\n",
        "\n",
        "    print(f'\\nTest Set Metrics:')\n",
        "    print(f'  Average Loss: {test_loss:.4f}')\n",
        "    print(f'  Accuracy: {correct}/{len(test_loader.dataset)} ({accuracy:.2f}%)')\n",
        "\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-OJXwjRQjGpu",
        "outputId": "b387e662-b26a-458c-bb8b-36d50728e503"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test Set Metrics:\n",
            "  Average Loss: -1.6029\n",
            "  Accuracy: 8040/10000 (80.40%)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "80.4"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ],
      "source": [
        "evaluate_model(test_model, device, test_dataloader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVXeXtWlrWjT"
      },
      "source": [
        "# Distillation Algorithm\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7d4Z3mfzskXM"
      },
      "source": [
        "Taken from https://github.com/ssnl/dataset-distillation/blob/master/train_distilled_image.py with adjustments to single model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIjwkk8AJeTs"
      },
      "source": [
        "- Initialize synthetic images from random noise (10 images for MNIST, 1 per class)\n",
        "- Learn both the synthetic data AND the learning rate\n",
        "- For each iteration:\n",
        "  - Reset model to fixed initialization\n",
        "  - Train on synthetic data for a few steps\n",
        "  - Evaluate on real training batch\n",
        "  - Backpropagate to update synthetic images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sbnFWWI40N3x"
      },
      "outputs": [],
      "source": [
        "from torch.func import functional_call\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "\n",
        "def distill_dataset(\n",
        "    model_class,\n",
        "    train_loader,\n",
        "    test_loader,\n",
        "    device,\n",
        "    num_classes=10,\n",
        "    images_per_class=1,\n",
        "    gradient_descent_steps=1, #step per epoch\n",
        "    distill_epochs=3, #epochs\n",
        "    distill_lr=0.01,\n",
        "    num_distill_iters=1000, #how many outer loops\n",
        "    log_interval=100, # interval in which we log (just for display)\n",
        "):\n",
        "    \"\"\"\n",
        "    Distill a dataset into a small set of synthetic images.\n",
        "    \"\"\"\n",
        "\n",
        "    num_classes = num_classes\n",
        "\n",
        "    # Learnable synthetic images\n",
        "    synthetic_data = torch.randn(\n",
        "        num_classes * images_per_class, 1, 28, 28,\n",
        "        device=device, requires_grad=True #grad enables the parameters to be trainable\n",
        "    )\n",
        "    synthetic_labels = torch.arange(num_classes, device=device).repeat_interleave(images_per_class)\n",
        "\n",
        "    # Learnable log learning rate (log to ensure positivity)\n",
        "    log_lr = torch.tensor(distill_lr, device=device).log().requires_grad_(True)\n",
        "\n",
        "    # Optimizer over synthetic images + log_lr\n",
        "    optimizer = torch.optim.Adam([synthetic_data, log_lr], lr=0.01)\n",
        "\n",
        "    # Base model and its initial parameters / state_dict\n",
        "    base_model = model_class().to(device)\n",
        "    initial_state_dict = base_model.state_dict()  # stores the initial weights of the model\n",
        "    initial_params = { # clone of all parameters to be used in the optimization loop\n",
        "        name: p.detach().clone()\n",
        "        for name, p in base_model.named_parameters()\n",
        "    }\n",
        "\n",
        "    train_iter = iter(train_loader) # do this to get batches one by one (we might loop through the entire dataset more than once)\n",
        "\n",
        "    print(f\"Starting distillation with {num_classes * images_per_class} synthetic images...\")\n",
        "    print(f\"Distill steps: {gradient_descent_steps}, Distill epochs: {distill_epochs}\")\n",
        "\n",
        "    for iteration in range(num_distill_iters):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Get a real batch\n",
        "        try:\n",
        "            real_data, real_labels = next(train_iter)\n",
        "        except StopIteration:\n",
        "            train_iter = iter(train_loader)\n",
        "            real_data, real_labels = next(train_iter)\n",
        "\n",
        "        real_data, real_labels = real_data.to(device), real_labels.to(device)\n",
        "\n",
        "        # Reset inner-loop params from initial_params (and make them require grad)\n",
        "        params = {\n",
        "            name: p.clone().detach().requires_grad_(True)\n",
        "            for name, p in initial_params.items()\n",
        "        }\n",
        "\n",
        "        current_lr = log_lr.exp()\n",
        "\n",
        "        # ----- Inner loop: train on synthetic data -----\n",
        "        for epoch in range(distill_epochs):\n",
        "          for step in range(gradient_descent_steps):\n",
        "            # forward pass on synthetic data using current params\n",
        "            new_synthetic_labels = functional_call(base_model, params, (synthetic_data,))\n",
        "\n",
        "            # compute inner loss on synthetic data\n",
        "            inner_loss = F.cross_entropy(new_synthetic_labels, synthetic_labels)\n",
        "\n",
        "            # compute gradients of inner loss w.r.t. current params\n",
        "            grads = torch.autograd.grad(\n",
        "              inner_loss,\n",
        "              list(params.values()),\n",
        "              create_graph=True\n",
        "            )\n",
        "\n",
        "            # gradient descent update on the parameter dictionary\n",
        "            params = {\n",
        "              name: param - current_lr * grad\n",
        "              for (name, param), grad in zip(params.items(), grads)\n",
        "            }\n",
        "        # ----- End of inner loop: train on synthetic data -----\n",
        "\n",
        "        # evaluate updated params on real data\n",
        "        real_new_labels = functional_call(base_model, params, (real_data,))\n",
        "        outer_loss = F.cross_entropy(real_new_labels, real_labels)\n",
        "\n",
        "        # Backprop to synthetic_data and log_lr\n",
        "        outer_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # ----- Logging / evaluation -----\n",
        "        if iteration % log_interval == 0 or iteration == num_distill_iters - 1:\n",
        "            # Detach current synthetic data and lr for evaluation so it doesn't\n",
        "            # extend the main graph\n",
        "            syn_eval = synthetic_data.detach()\n",
        "            syn_labels_eval = synthetic_labels.detach()\n",
        "            lr_eval = float(current_lr.detach().cpu())\n",
        "\n",
        "            # Fresh model for evaluation: train on synthetic images with normal SGD\n",
        "            eval_model = model_class().to(device)\n",
        "            eval_model.load_state_dict(initial_state_dict)\n",
        "            eval_model.train()\n",
        "            eval_opt = torch.optim.SGD(eval_model.parameters(), lr=lr_eval)\n",
        "\n",
        "            total_steps = gradient_descent_steps * distill_epochs #added this\n",
        "            for _ in range(total_steps):\n",
        "                out = eval_model(syn_eval)\n",
        "                loss = F.cross_entropy(out, syn_labels_eval)\n",
        "                eval_opt.zero_grad()\n",
        "                loss.backward()\n",
        "                eval_opt.step()\n",
        "\n",
        "            # Test accuracy\n",
        "            eval_model.eval()\n",
        "            correct, total = 0, 0\n",
        "            with torch.no_grad():\n",
        "                for data, target in test_loader:\n",
        "                    data, target = data.to(device), target.to(device)\n",
        "                    out = eval_model(data)\n",
        "                    pred = out.argmax(dim=1)\n",
        "                    correct += (pred == target).sum().item()\n",
        "                    total += target.size(0)\n",
        "\n",
        "            acc = 100.0 * correct / total\n",
        "            print(\n",
        "                f\"Iter {iteration:4d} | \"\n",
        "                f\"Outer Loss: {outer_loss.item():.4f} | \"\n",
        "                f\"LR: {current_lr.item():.5f} | \"\n",
        "                f\"Test Acc: {acc:.2f}%\"\n",
        "            )\n",
        "\n",
        "    return synthetic_data.detach(), synthetic_labels, log_lr.exp().detach()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "asysovmPM8eM",
        "outputId": "e4682860-b5d4-4963-f407-4ff6312b07d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "DISTILLING MNIST DATASET\n",
            "============================================================\n",
            "\n",
            "Starting distillation with 10 synthetic images...\n",
            "Distill steps: 1, Distill epochs: 3\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1649488342.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"=\"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m60\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m synthetic_data, synthetic_labels, learned_lr = distill_dataset(\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mmodel_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mQuantumLeNet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtrain_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-296255931.py\u001b[0m in \u001b[0;36mdistill_dataset\u001b[0;34m(model_class, train_loader, test_loader, device, num_classes, images_per_class, gradient_descent_steps, distill_epochs, distill_lr, num_distill_iters, log_interval)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;31m# compute gradients of inner loss w.r.t. current params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m             grads = torch.autograd.grad(\n\u001b[0m\u001b[1;32m     81\u001b[0m               \u001b[0minner_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m               \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched, materialize_grads)\u001b[0m\n\u001b[1;32m    501\u001b[0m         )\n\u001b[1;32m    502\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m         result = _engine_run_backward(\n\u001b[0m\u001b[1;32m    504\u001b[0m             \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m             \u001b[0mgrad_outputs_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    839\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    842\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mRuntimeError\u001b[0m: One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior."
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"DISTILLING MNIST DATASET\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "synthetic_data, synthetic_labels, learned_lr = distill_dataset(\n",
        "    model_class=QuantumLeNet,\n",
        "    train_loader=train_dataloader,\n",
        "    test_loader=test_dataloader,\n",
        "    device=device,\n",
        "    num_classes=10,\n",
        "    images_per_class=1,      # 1 image per class = 10 total images\n",
        "    gradient_descent_steps=1,          # Paper uses 1 step for MNIST\n",
        "    distill_epochs=3,         # Paper uses 3 epochs for MNIST\n",
        "    distill_lr=0.01,         # Initial learning rate\n",
        "    num_distill_iters=500,  # Number of distillation iterations\n",
        "    log_interval=100\n",
        ")\n",
        "\n",
        "print(f\"\\nDistillation complete!\")\n",
        "print(f\"Learned LR: {learned_lr.item():.6f}\")\n",
        "print(f\"Synthetic data shape: {synthetic_data.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kyWpTmRFNuB_"
      },
      "outputs": [],
      "source": [
        "def visualize_distilled_images(images, labels):\n",
        "    fig, axes = plt.subplots(1, 10, figsize=(15, 2))\n",
        "    for idx, (img, label) in enumerate(zip(images, labels)):\n",
        "        # Denormalize for visualization\n",
        "        img_show = img.cpu().squeeze() * 0.3081 + 0.1307\n",
        "        img_show = torch.clamp(img_show, 0, 1)\n",
        "\n",
        "        axes[idx].imshow(img_show, cmap='gray')\n",
        "        axes[idx].set_title(f'Class {label.item()}')\n",
        "        axes[idx].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('distilled_mnist.png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    print(\"Saved visualization to 'distilled_mnist.png'\")\n",
        "\n",
        "visualize_distilled_images(synthetic_data, synthetic_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hg3R-V_tca74"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TESTING: Paper-style training (few steps) on distilled data\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "test_model = NeuralNetwork().to(device)\n",
        "optimizer = torch.optim.SGD(test_model.parameters(), lr=learned_lr.item())\n",
        "\n",
        "total_steps = 3   # gradient_descent_steps * distill_epochs = 1 * 3\n",
        "\n",
        "for step in range(total_steps):\n",
        "    test_model.train()\n",
        "    optimizer.zero_grad()\n",
        "    output = test_model(synthetic_data)\n",
        "    loss = F.cross_entropy(output, synthetic_labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    print(f\"Step {step}: Loss = {loss.item():.4f}\")\n",
        "\n",
        "# Evaluate on test set\n",
        "test_model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data, target in test_dataloader:\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        output = test_model(data)\n",
        "        pred = output.argmax(dim=1)\n",
        "        correct += (pred == target).sum().item()\n",
        "        total += target.size(0)\n",
        "\n",
        "final_accuracy = 100.0 * correct / total\n",
        "print(f\"\\nFinal test accuracy (paper-style): {final_accuracy:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LfmgV4cvclm7"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}