{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Setup\n",
        "Using pytorch and pennylane to construct the novel QNN."
      ],
      "metadata": {
        "id": "Ux9_1gAOp4zT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "try:\n",
        "   import pennylane as qml\n",
        "except ImportError:\n",
        "  !pip install pennylane\n",
        "  import pennylane as qml\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "kernel_size = 5\n",
        "images = 1\n",
        "alpha = 0.5"
      ],
      "metadata": {
        "id": "x2gsBx9Tp-nY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "53c0df9a-6ef9-405b-a9ec-d08691a28c3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pennylane\n",
            "  Downloading pennylane-0.43.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from pennylane) (1.16.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from pennylane) (3.5)\n",
            "Collecting rustworkx>=0.14.0 (from pennylane)\n",
            "  Downloading rustworkx-0.17.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: autograd in /usr/local/lib/python3.12/dist-packages (from pennylane) (1.8.0)\n",
            "Collecting appdirs (from pennylane)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting autoray==0.8.0 (from pennylane)\n",
            "  Downloading autoray-0.8.0-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.12/dist-packages (from pennylane) (5.5.2)\n",
            "Collecting pennylane-lightning>=0.43 (from pennylane)\n",
            "  Downloading pennylane_lightning-0.43.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from pennylane) (2.32.4)\n",
            "Requirement already satisfied: tomlkit in /usr/local/lib/python3.12/dist-packages (from pennylane) (0.13.3)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from pennylane) (4.15.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from pennylane) (25.0)\n",
            "Collecting diastatic-malt (from pennylane)\n",
            "  Downloading diastatic_malt-2.15.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from pennylane) (2.0.2)\n",
            "Collecting scipy-openblas32>=0.3.26 (from pennylane-lightning>=0.43->pennylane)\n",
            "  Downloading scipy_openblas32-0.3.30.0.8-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (57 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m57.1/57.1 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: astunparse in /usr/local/lib/python3.12/dist-packages (from diastatic-malt->pennylane) (1.6.3)\n",
            "Requirement already satisfied: gast in /usr/local/lib/python3.12/dist-packages (from diastatic-malt->pennylane) (0.6.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.12/dist-packages (from diastatic-malt->pennylane) (3.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->pennylane) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->pennylane) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->pennylane) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->pennylane) (2025.10.5)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse->diastatic-malt->pennylane) (0.45.1)\n",
            "Requirement already satisfied: six<2.0,>=1.6.1 in /usr/local/lib/python3.12/dist-packages (from astunparse->diastatic-malt->pennylane) (1.17.0)\n",
            "Downloading pennylane-0.43.1-py3-none-any.whl (5.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autoray-0.8.0-py3-none-any.whl (934 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m934.3/934.3 kB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pennylane_lightning-0.43.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m63.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rustworkx-0.17.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading diastatic_malt-2.15.2-py3-none-any.whl (167 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m167.9/167.9 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy_openblas32-0.3.30.0.8-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m87.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: appdirs, scipy-openblas32, rustworkx, autoray, diastatic-malt, pennylane-lightning, pennylane\n",
            "Successfully installed appdirs-1.4.4 autoray-0.8.0 diastatic-malt-2.15.2 pennylane-0.43.1 pennylane-lightning-0.43.0 rustworkx-0.17.1 scipy-openblas32-0.3.30.0.8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pennylane/__init__.py:209: RuntimeWarning: PennyLane is not yet compatible with JAX versions > 0.6.2. You have version 0.7.2 installed. Please downgrade JAX to 0.6.2 to avoid runtime errors using python -m pip install jax~=0.6.0 jaxlib~=0.6.0\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classical CNN Layers\n"
      ],
      "metadata": {
        "id": "RXjCHRu9uOqc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Convolution 1\n",
        "C1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1, padding=2)\n",
        "x = torch.rand(images, 1, 28, 28)\n",
        "# activations = nn.ReLU()\n",
        "# activations = nn.Sigmoid()\n",
        "# activations = nn.Tanh()\n",
        "x1 = C1(x)\n",
        "print(\"C1 Shape:\", x1.shape)\n",
        "\n",
        "### Pooling 1\n",
        "P1 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "p1 = P1(x1)\n",
        "print(\"P1 Shape:\", p1.shape)\n",
        "\n",
        "### Convolution 2\n",
        "C2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1, padding=0)\n",
        "x2 = C2(p1)\n",
        "print(\"C2 Shape:\", x2.shape)\n",
        "\n",
        "### Pooling 2\n",
        "P2 = nn.AvgPool2d(kernel_size=1, stride=1)\n",
        "p2 = P2(x2)\n",
        "print(\"P2 Shape:\", p2.shape)\n",
        "\n",
        "### Full connections\n",
        "FC1 = nn.Linear(in_features=16*10*10, out_features=120)\n",
        "x3 = FC1(p2.view(-1, 16*10*10))\n",
        "print(\"F2 Shape\", x3.shape)\n",
        "\n",
        "FC2 = nn.Linear(in_features=120, out_features=64)\n",
        "x4 = FC2(x3)\n",
        "print(\"F3 Shape\",x4.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5yP3on8uOGa",
        "outputId": "80dfd3a0-4813-4fec-882e-c4c38126d4cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C1 Shape: torch.Size([1, 6, 28, 28])\n",
            "P1 Shape: torch.Size([1, 6, 14, 14])\n",
            "C2 Shape: torch.Size([1, 16, 10, 10])\n",
            "P2 Shape: torch.Size([1, 16, 10, 10])\n",
            "F2 Shape torch.Size([1, 120])\n",
            "F3 Shape torch.Size([1, 64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Residual Full Connection"
      ],
      "metadata": {
        "id": "clr-FUHp8qVU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rfc = nn.Linear(in_features=64, out_features=10)\n",
        "rfc_out = rfc(x4)\n",
        "\n",
        "print(\"F_residual Shape:\", rfc_out.shape)\n",
        "print(rfc_out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4XJiRD482lt",
        "outputId": "286911be-cbe4-46ab-fa79-7a7043c936d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F_residual Shape: torch.Size([1, 10])\n",
            "tensor([[-0.0176, -0.1110, -0.1148, -0.1015, -0.0327,  0.1289, -0.0133, -0.0727,\n",
            "          0.0326,  0.1240]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##QNN"
      ],
      "metadata": {
        "id": "RUZQzp-r8wow"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#QNN Setup\n",
        "\n",
        "def init_random_hermitian_observable(n_qubits):\n",
        "  Hermitian = torch.randn(n_qubits, 4)\n",
        "  return Hermitian"
      ],
      "metadata": {
        "id": "cc-rNf2z83iy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Actual Quantum Layer - Kris\n",
        "n_qubits = 6 #2^6 = 64, so will embed the length 64 vector\n",
        "entangling_layers = 3 # The PQC strongly entangling layers happens 3 times.\n",
        "fixed_hermitians = True\n",
        "\n",
        "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "I = torch.tensor([[1,0],[0,1]])\n",
        "X = torch.tensor([[0,1],[1,0]])\n",
        "Y = torch.tensor([[0,-1j],[1j,0]])\n",
        "Z = torch.tensor([[1,0],[0,-1]])\n",
        "\n",
        "# Define Quantum Circuit and Link with PyTorch\n",
        "@qml.qnode(dev, interface='torch')\n",
        "def qnn_circuit(inputs, weights, hermitians):\n",
        "  # Amplitude Embedding\n",
        "  qml.AmplitudeEmbedding(inputs, wires=range(n_qubits), normalize=True)\n",
        "\n",
        "  # Strong Entangling Layers\n",
        "  qml.StronglyEntanglingLayers(weights, wires=range(n_qubits))\n",
        "\n",
        "  # Measure Hermitian Observable\n",
        "\n",
        "  expvals = []\n",
        "\n",
        "  for q in range(n_qubits):\n",
        "    ai, ax, ay, az = hermitians[q]\n",
        "    observable = (ai*I) + (ax*X) + (ay*Y) + (az*Z)\n",
        "\n",
        "    expvals.append(qml.expval(qml.Hermitian(observable, q)))\n",
        "\n",
        "  return expvals\n",
        "\n",
        "# Define weights and have 3 layers\n",
        "# This defines 3 repetitions of the entangling layers on the 6 qubits, with 3 weights\n",
        "weight_shapes = {\n",
        "    \"weights\":(entangling_layers, n_qubits, 3),\n",
        "    \"hermitians\":(n_qubits, 4)\n",
        "}\n",
        "\n",
        "# Creates the quantum layer\n",
        "qnn_layer = qml.qnn.TorchLayer(qnn_circuit, weight_shapes)\n",
        "\n",
        "#Initialize Hermitians randomly\n",
        "with torch.no_grad():\n",
        "    hermitian_init = init_random_hermitian_observable(n_qubits)\n",
        "    qnn_layer.hermitians.copy_(hermitian_init)\n",
        "\n",
        "if(fixed_hermitians):\n",
        "  qnn_layer.hermitians.requires_grad_(False)\n",
        "\n",
        "# Passes the 64 inputs into the quantum layer\n",
        "qnn = qnn_layer(x4)\n",
        "print(\"Quantum Layer Shape:\", qnn.shape)\n",
        "\n",
        "# Final qnn classification layer, converts the 6 qubits to 10 outputs\n",
        "qnnfcl = nn.Linear(in_features=6, out_features=10)\n",
        "qnn_out = qnnfcl(qnn)\n",
        "print(\"Final Quantum Layer Shape:\",qnn_out.shape)\n",
        "print(qml.draw(qnn_circuit, level='device')(x4[0], qnn_layer.weights, qnn_layer.hermitians))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MHygj87BKe1h",
        "outputId": "9418e030-b39d-4e9a-8ceb-47004527dc01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quantum Layer Shape: torch.Size([1, 6])\n",
            "Final Quantum Layer Shape: torch.Size([1, 10])\n",
            "0: â”€â•­|Î¨âŸ©â”€â”€Rot(0.58,6.15,4.68)â”€â•­â—â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•­Xâ”€â”€Rot(4.74,6.20,3.70)â”€â•­â—â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•­X Â·Â·Â·\n",
            "1: â”€â”œ|Î¨âŸ©â”€â”€Rot(5.15,2.30,4.49)â”€â•°Xâ”€â•­â—â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚â”€â”€â”€Rot(4.89,5.18,5.37)â”€â”‚â”€â”€â•­â—â”€â”€â”€â”€â”€â”€â”€â”‚â”€ Â·Â·Â·\n",
            "2: â”€â”œ|Î¨âŸ©â”€â”€Rot(5.79,3.92,1.39)â”€â”€â”€â”€â•°Xâ”€â•­â—â”€â”€â”€â”€â”€â”€â”€â”‚â”€â”€â”€Rot(1.75,3.50,2.76)â”€â•°Xâ”€â”‚â”€â”€â•­â—â”€â”€â”€â”€â”‚â”€ Â·Â·Â·\n",
            "3: â”€â”œ|Î¨âŸ©â”€â”€Rot(0.54,4.89,0.10)â”€â”€â”€â”€â”€â”€â”€â•°Xâ”€â•­â—â”€â”€â”€â”€â”‚â”€â”€â”€Rot(0.70,0.94,2.98)â”€â”€â”€â”€â•°Xâ”€â”‚â”€â”€â•­â—â”€â”‚â”€ Â·Â·Â·\n",
            "4: â”€â”œ|Î¨âŸ©â”€â”€Rot(5.38,2.34,0.29)â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•°Xâ”€â•­â—â”€â”‚â”€â”€â”€Rot(6.20,1.76,3.23)â”€â”€â”€â”€â”€â”€â”€â•°Xâ”€â”‚â”€â”€â•°â— Â·Â·Â·\n",
            "5: â”€â•°|Î¨âŸ©â”€â”€Rot(4.43,3.71,5.75)â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•°Xâ”€â•°â—â”€â”€Rot(4.15,4.06,2.69)â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•°Xâ”€â”€â”€ Â·Â·Â·\n",
            "\n",
            "0: Â·Â·Â· â”€â”€Rot(5.21,3.24,5.06)â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•­â—â”€â”€â”€â”€â”€â”€â”€â•­Xâ”€â”€â”€â”€â”€â”€â”€â”¤  <ğ“—(M0)>\n",
            "1: Â·Â·Â· â”€â•­Xâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€Rot(6.22,5.55,6.09)â”€â”‚â”€â”€â•­â—â”€â”€â”€â”€â”‚â”€â”€â•­Xâ”€â”€â”€â”€â”¤  <ğ“—(M1)>\n",
            "2: Â·Â·Â· â”€â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€Rot(4.47,0.65,1.24)â”€â”‚â”€â”€â”‚â”€â”€â•­â—â”€â”‚â”€â”€â”‚â”€â”€â•­Xâ”€â”¤  <ğ“—(M2)>\n",
            "3: Â·Â·Â· â”€â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€Rot(0.36,1.48,5.22)â”€â•°Xâ”€â”‚â”€â”€â”‚â”€â”€â•°â—â”€â”‚â”€â”€â”‚â”€â”€â”¤  <ğ“—(M3)>\n",
            "4: Â·Â·Â· â”€â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€Rot(0.91,5.71,4.29)â”€â”€â”€â”€â•°Xâ”€â”‚â”€â”€â”€â”€â”€â•°â—â”€â”‚â”€â”€â”¤  <ğ“—(M4)>\n",
            "5: Â·Â·Â· â”€â•°â—â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€Rot(1.65,5.57,1.66)â”€â”€â”€â”€â”€â”€â”€â•°Xâ”€â”€â”€â”€â”€â”€â”€â•°â—â”€â”¤  <ğ“—(M5)>\n",
            "\n",
            "M0 = \n",
            "tensor([[-2.4458+0.0000j,  0.7362+0.2072j],\n",
            "        [ 0.7362-0.2072j,  0.5346+0.0000j]])\n",
            "M1 = \n",
            "tensor([[-0.0352+0.0000j, -1.5450-1.0492j],\n",
            "        [-1.5450+1.0492j,  0.9629+0.0000j]])\n",
            "M2 = \n",
            "tensor([[-2.2864+0.0000j,  0.5057+0.2273j],\n",
            "        [ 0.5057-0.2273j, -1.8391+0.0000j]])\n",
            "M3 = \n",
            "tensor([[-1.1274+0.0000j, -2.3028-0.9305j],\n",
            "        [-2.3028+0.9305j,  0.1139+0.0000j]])\n",
            "M4 = \n",
            "tensor([[-0.8166+0.0000j,  0.0563+1.0126j],\n",
            "        [ 0.0563-1.0126j, -0.1082+0.0000j]])\n",
            "M5 = \n",
            "tensor([[ 0.7726+0.0000j,  0.9339-2.4911j],\n",
            "        [ 0.9339+2.4911j, -0.1111+0.0000j]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Output"
      ],
      "metadata": {
        "id": "-dRp1ogM84so"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Combines the two outputs using a sum based on alpha\n",
        "out = (rfc_out * (1-alpha)) + (qnn_out * alpha)\n",
        "\n",
        "print(out)\n",
        "print(out.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvE2cerv88cO",
        "outputId": "0cc8b4f6-aa19-4ce2-c37d-b91661d9a0d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.5556, -0.4546, -0.5087,  0.0859,  0.0914,  0.4580,  0.5325,  0.3393,\n",
            "          0.3355,  0.4236]], grad_fn=<AddBackward0>)\n",
            "torch.Size([1, 10])\n"
          ]
        }
      ]
    }
  ]
}